{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring some intrinsic dimension (ID) and local intrinsic dimension (LID) estimators for high-dimensional data.\n",
    "\n",
    "### References\n",
    "1. Ma, Xingjun, et al. \"Characterizing adversarial subspaces using local intrinsic dimensionality.\" arXiv preprint arXiv:1801.02613 (2018).\n",
    "1. Amsaleg, Laurent, et al. \"Estimating local intrinsic dimensionality.\" Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2015.\n",
    "1. Ansuini, Alessio, et al. \"Intrinsic dimension of data representations in deep neural networks.\" arXiv preprint arXiv:1905.12784 (2019).\n",
    "1. Carter, Kevin M., Raviv Raich, and Alfred O. Hero III. \"On local intrinsic dimension estimation and its applications.\" IEEE Transactions on Signal Processing 58.2 (2009): 650-663.\n",
    "1. Levina, Elizaveta, and Peter J. Bickel. \"Maximum likelihood estimation of intrinsic dimension.\" Advances in neural information processing systems. 2005.\n",
    "1. Facco, Elena, et al. \"Estimating the intrinsic dimension of datasets by a minimal neighborhood information.\" Scientific reports 7.1 (2017): 12140."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LID estimation method from [1] and [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pynndescent import NNDescent\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from multiprocessing import cpu_count\n",
    "from metrics_custom import (\n",
    "    distance_SNN, \n",
    "    neighborhood_membership_vectors\n",
    ")\n",
    "from generate_data import MFA_model\n",
    "from lid_estimators import (\n",
    "    lid_mle_amsaleg, \n",
    "    id_two_nearest_neighbors\n",
    ")\n",
    "from utils import remove_self_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress annoying numba warning\n",
    "import warnings\n",
    "from numba import NumbaPendingDeprecationWarning\n",
    "warnings.filterwarnings('ignore', '', NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "num_proc = max(cpu_count() - 2, 1)\n",
    "seed_rng = np.random.randint(1, high=10000)\n",
    "K = 20\n",
    "n_neighbors = max(K + 2, 20)\n",
    "rho = 0.5\n",
    "metric_primary = 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data according to a mixture of factor analysis (MFA) model\n",
    "np.random.seed(seed_rng)\n",
    "\n",
    "# number of mixture components\n",
    "n_components = 10\n",
    "# dimension of the observed space\n",
    "dim = 500\n",
    "\n",
    "# dimension of the latent space. This determines the local intrinsic dimension\n",
    "# dim_latent = 10\n",
    "# model = MFA_model(n_components, dim, dim_latent=dim_latent, seed_rng=seed_rng)\n",
    "\n",
    "# Can specify a range for the latent dimension instead of a single value\n",
    "dim_latent_range = (10, 20)\n",
    "model = MFA_model(n_components, dim, dim_latent_range=dim_latent_range, seed_rng=seed_rng)\n",
    "\n",
    "# Generate data from the model\n",
    "N = 1000\n",
    "N_test = 100\n",
    "data, labels = model.generate_data(N)\n",
    "data_test, labels_test = model.generate_data(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 27 21:59:36 2019 Building RP forest with 7 trees\n",
      "Wed Nov 27 21:59:36 2019 parallel NN descent for 10 iterations\n",
      "\t 0  /  10\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n"
     ]
    }
   ],
   "source": [
    "# Construct an approximate nearest neighbor (ANN) index to query nearest neighbors\n",
    "params = {\n",
    "    'metric': metric_primary, \n",
    "    'n_neighbors': n_neighbors,\n",
    "    'rho': rho,\n",
    "    'random_state': seed_rng,\n",
    "    'n_jobs': num_proc, \n",
    "    'verbose': True\n",
    "}\n",
    "index = NNDescent(data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the K nearest neighbors of each point. \n",
    "# Since each point will be selected as its own nearest neighbor, we query for `K+1` neighbors and ignore the self neighbors\n",
    "nn_indices_, nn_distances_ = index.query(data, k=(K + 1))\n",
    "\n",
    "# Remove each point from it's own neighborhood set\n",
    "nn_indices, nn_distances = remove_self_neighbors(nn_indices_, nn_distances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean LID = 11.1020\n"
     ]
    }
   ],
   "source": [
    "# Calculate the local intrinsic dimension in the neighborhood of each point\n",
    "lid = lid_mle_amsaleg(nn_distances)\n",
    "print(\"Mean LID = {:.4f}\".format(np.mean(lid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles of the LID distribution:\n",
      "0.0\t2.5475\n",
      "2.5\t4.3386\n",
      "25.0\t8.6749\n",
      "50.0\t10.7200\n",
      "75.0\t13.2346\n",
      "97.5\t19.1734\n",
      "100.0\t25.2169\n"
     ]
    }
   ],
   "source": [
    "p = [0, 2.5, 25, 50, 75, 97.5, 100]\n",
    "out = np.percentile(lid, p)\n",
    "print(\"Percentiles of the LID distribution:\")\n",
    "for a, b in zip(p, out):\n",
    "    print(\"{:.1f}\\t{:.4f}\".format(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrinsic dimension estimation using the Two-NN method [6, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic dimension estimated using the two-NN method = 14.9503\n"
     ]
    }
   ],
   "source": [
    "id = id_two_nearest_neighbors(nn_distances)\n",
    "print(\"Intrinsic dimension estimated using the two-NN method = {:.4f}\".format(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the intrinsic dimension and local intrinsic dimension estimates are below `20` despite the (ambient) dimension of the data being `500`. This is consistent with the underlying MFA model whose latent dimension from each component is chosen uniformly from the range `[10, 20]`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
