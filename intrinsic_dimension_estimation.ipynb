{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring some intrinsic dimension (ID) and local intrinsic dimension (LID) estimators for high-dimensional data.\n",
    "\n",
    "### References\n",
    "1. Ma, Xingjun, et al. \"Characterizing adversarial subspaces using local intrinsic dimensionality.\" arXiv preprint arXiv:1801.02613 (2018).\n",
    "1. Amsaleg, Laurent, et al. \"Estimating local intrinsic dimensionality.\" Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2015.\n",
    "1. Ansuini, Alessio, et al. \"Intrinsic dimension of data representations in deep neural networks.\" arXiv preprint arXiv:1905.12784 (2019).\n",
    "1. Carter, Kevin M., Raviv Raich, and Alfred O. Hero III. \"On local intrinsic dimension estimation and its applications.\" IEEE Transactions on Signal Processing 58.2 (2009): 650-663.\n",
    "1. Levina, Elizaveta, and Peter J. Bickel. \"Maximum likelihood estimation of intrinsic dimension.\" Advances in neural information processing systems. 2005.\n",
    "1. Facco, Elena, et al. \"Estimating the intrinsic dimension of datasets by a minimal neighborhood information.\" Scientific reports 7.1 (2017): 12140."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LID estimation method from [1] and [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pynndescent import NNDescent\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from metrics_custom import remove_self_neighbors\n",
    "from generate_data import MFA_model\n",
    "from lid_estimators import (\n",
    "    lid_mle_amsaleg, \n",
    "    id_two_nearest_neighbors, \n",
    "    estimate_intrinsic_dimension\n",
    ")\n",
    "from dimension_reduction_methods import pca_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress annoying numba warning\n",
    "import warnings\n",
    "from numba import NumbaPendingDeprecationWarning\n",
    "warnings.filterwarnings('ignore', '', NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "num_proc = max(cpu_count() - 2, 1)\n",
    "seed_rng = np.random.randint(1, high=10000)\n",
    "K = 20\n",
    "n_neighbors = max(K + 2, 20)\n",
    "rho = 0.5\n",
    "metric_primary = 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data according to a mixture of factor analysis (MFA) model\n",
    "np.random.seed(seed_rng)\n",
    "\n",
    "# number of mixture components\n",
    "n_components = 10\n",
    "# dimension of the observed space\n",
    "dim = 500\n",
    "\n",
    "# dimension of the latent space. This determines the local intrinsic dimension\n",
    "# dim_latent = 10\n",
    "# model = MFA_model(n_components, dim, dim_latent=dim_latent, seed_rng=seed_rng)\n",
    "\n",
    "# Can specify a range for the latent dimension instead of a single value\n",
    "dim_latent_range = (10, 20)\n",
    "model = MFA_model(n_components, dim, dim_latent_range=dim_latent_range, seed_rng=seed_rng)\n",
    "\n",
    "# Generate data from the model\n",
    "N = 1000\n",
    "N_test = 100\n",
    "data, labels = model.generate_data(N)\n",
    "data_test, labels_test = model.generate_data(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 24 10:18:46 2019 Building RP forest with 7 trees\n",
      "Tue Dec 24 10:18:47 2019 parallel NN descent for 10 iterations\n",
      "\t 0  /  10\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\t 3  /  10\n"
     ]
    }
   ],
   "source": [
    "# Construct an approximate nearest neighbor (ANN) index to query nearest neighbors\n",
    "params = {\n",
    "    'metric': metric_primary, \n",
    "    'n_neighbors': n_neighbors,\n",
    "    'rho': rho,\n",
    "    'random_state': seed_rng,\n",
    "    'n_jobs': num_proc, \n",
    "    'verbose': True\n",
    "}\n",
    "index = NNDescent(data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the K nearest neighbors of each point. \n",
    "# Since each point will be selected as its own nearest neighbor, we query for `K+1` neighbors and ignore the self neighbors\n",
    "nn_indices_, nn_distances_ = index.query(data, k=(K + 1))\n",
    "\n",
    "# Remove each point from it's own neighborhood set\n",
    "nn_indices, nn_distances = remove_self_neighbors(nn_indices_, nn_distances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean LID = 10.5029\n"
     ]
    }
   ],
   "source": [
    "# Calculate the local intrinsic dimension in the neighborhood of each point\n",
    "lid = lid_mle_amsaleg(nn_distances)\n",
    "print(\"Mean LID = {:.4f}\".format(np.mean(lid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles of the LID distribution:\n",
      "0.0\t1.8432\n",
      "2.5\t4.3697\n",
      "25.0\t8.4421\n",
      "50.0\t10.2791\n",
      "75.0\t12.1687\n",
      "97.5\t17.8415\n",
      "100.0\t24.5904\n"
     ]
    }
   ],
   "source": [
    "p = [0, 2.5, 25, 50, 75, 97.5, 100]\n",
    "out = np.percentile(lid, p)\n",
    "print(\"Percentiles of the LID distribution:\")\n",
    "for a, b in zip(p, out):\n",
    "    print(\"{:.1f}\\t{:.4f}\".format(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrinsic dimension estimation using the Two-NN method [6, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic dimension estimated using the two-NN method = 14.7769\n"
     ]
    }
   ],
   "source": [
    "id = id_two_nearest_neighbors(nn_distances)\n",
    "print(\"Intrinsic dimension estimated using the two-NN method = {:.4f}\".format(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the intrinsic dimension and local intrinsic dimension estimates are below `20` despite the (ambient) dimension of the data being `500`. This is consistent with the underlying MFA model whose latent dimension from each component is chosen uniformly from the range `[10, 20]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic dimension estimates from both the methods: 14.7769, 10.2791\n"
     ]
    }
   ],
   "source": [
    "# Testing the wrapper function which essentially does the above steps under the hood\n",
    "id1 = estimate_intrinsic_dimension(data, method='two_nn', n_neighbors=K, n_jobs=num_proc, seed_rng=seed_rng)\n",
    "id2 = estimate_intrinsic_dimension(data, method='lid_mle', n_neighbors=K, n_jobs=num_proc, seed_rng=seed_rng)\n",
    "\n",
    "print(\"Intrinsic dimension estimates from both the methods: {:.4f}, {:.4f}\".format(id1, id2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 35000. Number of dimensions = 784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data_all, labels_all = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# Scale the feature values to the range [0, 1]\n",
    "data_all = data_all / 255.\n",
    "\n",
    "# Create a random, stratified train/test split\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed_rng)\n",
    "data = labels = None\n",
    "data_test = labels_test = None\n",
    "for index_tr, index_te in sss.split(data_all, labels_all):\n",
    "    data = data_all[index_tr, :]\n",
    "    labels = labels_all[index_tr]\n",
    "    data_test = data_all[index_te, :]\n",
    "    labels_test = labels_all[index_te]\n",
    "\n",
    "print(\"Number of train samples = {:d}. Number of dimensions = {:d}\".format(*data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dimension_reduction_methods:Number of nonzero singular values in the data matrix = 784\n",
      "INFO:dimension_reduction_methods:Number of principal components accounting for 99.0 percent of the data variance = 330\n",
      "INFO:dimension_reduction_methods:Dimension of the PCA transformed data = 330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the PCA transformed data = 330\n",
      "Intrinsic dimension estimate using the two-NN method = 14.2012\n",
      "Intrinsic dimension estimate using the maximum likelihood method = 12.5246\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA as a preprocessing step to retain dimensions that account for 99% of the variance\n",
    "data_proj, mean_data, transform_pca = pca_wrapper(data, cutoff=0.99, seed_rng=seed_rng)\n",
    "print(\"Dimension of the PCA transformed data = {:d}\".format(data_proj.shape[1]))\n",
    "\n",
    "id = estimate_intrinsic_dimension(data_proj, method='two_nn', n_neighbors=2, n_jobs=num_proc, \n",
    "                                  seed_rng=seed_rng)\n",
    "print(\"Intrinsic dimension estimate using the two-NN method = {:.4f}\".format(id))\n",
    "\n",
    "id = estimate_intrinsic_dimension(data_proj, method='lid_mle', neighborhood_constant=0.4, n_jobs=num_proc, \n",
    "                                  seed_rng=seed_rng)\n",
    "print(\"Intrinsic dimension estimate using the maximum likelihood method = {:.4f}\".format(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 50000. Number of dimensions = 3072\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "data_path_local = '/Users/jayaram/Documents/research/data/cifar-10-batches-py'\n",
    "if data_path_local not in sys.path:\n",
    "    sys.path.append(data_path_local)\n",
    "    \n",
    "from load_cifar10_data import load_cifar_10_data\n",
    "data, labels, _, data_test, labels_test, _, _ = load_cifar_10_data(data_path_local, vectorize=True)\n",
    "\n",
    "# Scale the feature values to the range [0, 1]\n",
    "data = data / 255.\n",
    "data_test = data_test / 255.\n",
    "print(\"Number of train samples = {:d}. Number of dimensions = {:d}\".format(*data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dimension_reduction_methods:Number of nonzero singular values in the data matrix = 3072\n",
      "INFO:dimension_reduction_methods:Number of principal components accounting for 99.0 percent of the data variance = 658\n",
      "INFO:dimension_reduction_methods:Dimension of the PCA transformed data = 658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the PCA transformed data = 658\n",
      "Intrinsic dimension estimate using the two-NN method = 7.9672\n",
      "Intrinsic dimension estimate using the maximum likelihood method = 26.6976\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA as a preprocessing step to retain dimensions that account for 99% of the variance\n",
    "data_proj, mean_data, transform_pca = pca_wrapper(data, cutoff=0.99, seed_rng=seed_rng)\n",
    "print(\"Dimension of the PCA transformed data = {:d}\".format(data_proj.shape[1]))\n",
    "\n",
    "id = estimate_intrinsic_dimension(data_proj, method='two_nn', n_neighbors=2, n_jobs=num_proc, \n",
    "                                  seed_rng=seed_rng)\n",
    "print(\"Intrinsic dimension estimate using the two-NN method = {:.4f}\".format(id))\n",
    "\n",
    "id = estimate_intrinsic_dimension(data_proj, method='lid_mle', neighborhood_constant=0.4, n_jobs=num_proc, \n",
    "                                  seed_rng=seed_rng)\n",
    "print(\"Intrinsic dimension estimate using the maximum likelihood method = {:.4f}\".format(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVHN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 73257. Number of dimensions = 3072\n"
     ]
    }
   ],
   "source": [
    "# Load the data from a local copy\n",
    "data_path_local = '/Users/jayaram/Documents/research/data/SVHN'\n",
    "if data_path_local not in sys.path:\n",
    "    sys.path.append(data_path_local)\n",
    "    \n",
    "from preprocess_svhn import load_images, normalize_images\n",
    "\n",
    "imgs_train, imgs_test = load_images(data_path_local)\n",
    "data, labels = normalize_images(imgs_train, vectorize=True)\n",
    "data_test, labels_test = normalize_images(imgs_test, vectorize=True)\n",
    "\n",
    "print(\"Number of train samples = {:d}. Number of dimensions = {:d}\".format(*data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dimension_reduction_methods:Number of nonzero singular values in the data matrix = 3072\n",
      "INFO:dimension_reduction_methods:Number of principal components accounting for 99.5 percent of the data variance = 266\n",
      "INFO:dimension_reduction_methods:Dimension of the PCA transformed data = 266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the PCA transformed data = 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayaram/Documents/research/code/KNN-anomaly-detection/lid_estimators.py:48: RuntimeWarning: overflow encountered in true_divide\n",
      "  nn_ratio = knn_distances[:, 1] / np.clip(knn_distances[:, 0], sys.float_info.min, None)\n",
      "/anaconda3/envs/knn_expts/lib/python3.7/site-packages/numpy/lib/function_base.py:2445: RuntimeWarning: invalid value encountered in subtract\n",
      "  X -= avg[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic dimension estimate using the two-NN method = nan\n",
      "Intrinsic dimension estimate using the maximum likelihood method = 18.7266\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA as a preprocessing step to retain dimensions that account for 99.5% of the variance\n",
    "data_proj, mean_data, transform_pca = pca_wrapper(data, cutoff=0.995, seed_rng=seed_rng)\n",
    "print(\"Dimension of the PCA transformed data = {:d}\".format(data_proj.shape[1]))\n",
    "\n",
    "id = estimate_intrinsic_dimension(data_proj, method='two_nn', n_neighbors=2, n_jobs=num_proc, \n",
    "                                  seed_rng=seed_rng)\n",
    "print(\"Intrinsic dimension estimate using the two-NN method = {:.4f}\".format(id))\n",
    "\n",
    "id = estimate_intrinsic_dimension(data_proj, method='lid_mle', neighborhood_constant=0.4, n_jobs=num_proc, \n",
    "                                  seed_rng=seed_rng)\n",
    "print(\"Intrinsic dimension estimate using the maximum likelihood method = {:.4f}\".format(id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
