{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom distance metrics for 3rd order tensors\n",
    "#### Norm-based distance metrics\n",
    "Suppose $\\mathbf{X} \\in \\mathbb{R}^{l \\times m \\times n}$ and $\\mathbf{Y} \\in \\mathbb{R}^{l \\times m \\times n}$ are the two tensors, we define the distance metric between them, induced by a general norm, as\n",
    "\n",
    "\\begin{eqnarray}\n",
    "d(\\mathbf{X}, \\mathbf{Y}) &=& \\|\\mathbf{X} - \\mathbf{Y}\\|_{p,q,r} \\\\\n",
    "&=& \\left( \\sum_{i=1}^l \\left( \\sum_{j=1}^m \\left( \\sum_{k=1}^n |X_{ijk} \\,-\\, Y_{ijk}|^r \\right)^{\\frac{q}{r}} \\right)^{\\frac{p}{q}} \\right)^{\\frac{1}{p}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "This can be seen as a direct extension of the entrywise matrix norms defined, for example, [here](https://en.wikipedia.org/wiki/Matrix_norm#L2,1_and_Lp,q_norms). The norm is defined by the parameters $p, q, r$, which should be integers greater than $0$. The following three special cases of the distance metric should be useful in practice for high dimensional data:  \n",
    "- $p = q = r = 1$: Similar to the Manhattan distance between vectors.\n",
    "- $p = q = r = 2$: Similar to the Euclidean distance between vectors or Frobenius norm distance between matrices.\n",
    "- $p = 1, q = r = 2$: In this case, the distance is the sum of Frobenius norm distances between the matrix slices along the second and third dimensions.\n",
    "\n",
    "#### Cosine angular distance\n",
    "This is a distance measure between two tensors derived from the cosine similarity. Note that this may not be a distance metric in the true sense because the triangle inequality may not be satisfied. Recall that for two vector inputs $\\mathbf{a}$ and $\\mathbf{b}$, suppose $S_{\\cos}(\\mathbf{a}, \\mathbf{b})$ is their cosine similarity in the range $[-1, 1]$, the angular distance between them is defined as $\\,d_a(\\mathbf{a}, \\mathbf{b}) = \\frac{1}{\\pi} \\,\\arccos(S_{\\cos}(\\mathbf{a}, \\mathbf{b}))$, which has range $[0, 1]$. \n",
    "\n",
    "The cosine similarity between two matrices $\\mathbf{A}$ and $\\mathbf{B}$ of compatible dimensions is defined as\n",
    "\n",
    "\\begin{eqnarray}\n",
    "S_{\\cos}(\\mathbf{A}, \\mathbf{B}) &=& \\frac{<\\mathbf{A}, \\mathbf{B}>}{\\|\\mathbf{A}\\|_F \\,\\|\\mathbf{B}\\|_F} \\\\ \n",
    "&=& \\frac{tr(\\mathbf{A}^T \\,\\mathbf{B})}{\\sqrt{tr(\\mathbf{A}^T \\,\\mathbf{A}) tr(\\mathbf{B}^T \\,\\mathbf{B})}}.\n",
    "\\end{eqnarray}\n",
    "\n",
    "In the case of tensors, we first calculate the average cosine similarity between the individual matrix slices (along the second and third dimension) as follows,\n",
    "\n",
    "$$\n",
    "S_{\\cos}(\\mathbf{X}, \\mathbf{Y}) ~=~ \\frac{1}{l} \\sum_{i=1}^l \\frac{tr(\\mathbf{X_i}^T \\,\\mathbf{Y_i})}{\\sqrt{tr(\\mathbf{X_i}^T \\,\\mathbf{X_i}) tr(\\mathbf{Y_i}^T \\,\\mathbf{Y_i})}},\n",
    "$$  \n",
    "where $\\mathbf{X_i}$ and $\\mathbf{Y_i}$ are the matrix slices of size $m \\times n$. The angular cosine distance between the tensors is then defined as\n",
    "\n",
    "$$d_a(\\mathbf{X}, \\mathbf{Y}) ~=~ \\arccos(S_{\\cos}(\\mathbf{X}, \\mathbf{Y}))$$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import metrics_custom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = q = r = 1: distance = 31.633253\n",
      "p = q = r = 2: distance = 8.606620\n",
      "p = 1, q = r = 2: distance = 12.138543\n",
      "Cosine angular distance = 1.632498\n"
     ]
    }
   ],
   "source": [
    "# Shape of the tensors. Specified as an integer instead of a tuple to avoid errors related to `numba`\n",
    "shape = (2, 3, 4)\n",
    "\n",
    "# xt = 2 * np.ones(shape)\n",
    "xt = np.random.randn(*shape)\n",
    "# Flatten into a vector before calling the distance function\n",
    "x = xt.reshape(-1)\n",
    "\n",
    "# yt = np.ones(shape)\n",
    "yt = np.random.randn(*shape)\n",
    "y = yt.reshape(-1)\n",
    "\n",
    "# The norm parameters `p, q, r` are specified as a tuple to the keyword argument `norm_type`. \n",
    "# For example, `p = q = r = 2` is specified as `norm_type=(2, 2, 2)`.\n",
    "d = metrics_custom.distance_norm_3tensors(x, y, shape=shape, norm_type=(1, 1, 1))\n",
    "print(\"p = q = r = 1: distance = {:f}\".format(d))\n",
    "\n",
    "d = metrics_custom.distance_norm_3tensors(x, y, shape=shape, norm_type=(2, 2, 2))\n",
    "print(\"p = q = r = 2: distance = {:f}\".format(d))\n",
    "\n",
    "d = metrics_custom.distance_norm_3tensors(x, y, shape=shape, norm_type=(1, 2, 2))\n",
    "print(\"p = 1, q = r = 2: distance = {:f}\".format(d))\n",
    "\n",
    "d = metrics_custom.distance_angular_3tensors(x, y, shape=shape)\n",
    "print(\"Cosine angular distance = {:f}\".format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special cases of the norm-based distance metrics\n",
    "It can be shown that when $p = \\infty$ and $q, r < \\infty$, the distance metric reduces to\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{X} - \\mathbf{Y}\\|_{\\infty,q,r} = \\left(\\max_{i = 1, \\cdots, l} \\sum_{j=1}^m \\left( \\sum_{k=1}^n |X_{ijk} \\,-\\, Y_{ijk}|^r \\right)^{\\frac{q}{r}} \\right)^{\\frac{1}{q}}\n",
    "$$\n",
    "\n",
    "The following two special cases will be useful in practice:\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{X} - \\mathbf{Y}\\|_{\\infty,2,2} = \\sqrt{\\max_{i = 1, \\cdots, l} \\sum_{j=1}^m \\sum_{k=1}^n (X_{ijk} \\,-\\, Y_{ijk})^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{X} - \\mathbf{Y}\\|_{\\infty,1,1} = \\max_{i = 1, \\cdots, l} \\sum_{j=1}^m \\sum_{k=1}^n |X_{ijk} \\,-\\, Y_{ijk}|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = infty, q = 2, r = 2: distance = 6.517490\n",
      "p = infty, q = 1, r = 1: distance = 18.260022\n"
     ]
    }
   ],
   "source": [
    "# The special value `p = -1` is used to specify the infinite case\n",
    "d = metrics_custom.distance_norm_3tensors(x, y, shape=shape, norm_type=(-1, 2, 2))\n",
    "print(\"p = infty, q = 2, r = 2: distance = {:f}\".format(d))\n",
    "\n",
    "d = metrics_custom.distance_norm_3tensors(x, y, shape=shape, norm_type=(-1, 1, 1))\n",
    "print(\"p = infty, q = 1, r = 1: distance = {:f}\".format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Nearest Neighbor distance\n",
    "The SNN similarity measure is based on the rankings induced by a primary distance metric such as Euclidean, cosine etc. Suppose we have a set of points $\\mathcal{X} = \\lbrace\\mathbf{x_1}, \\cdots, \\mathbf{x_N}\\rbrace \\subset \\mathbb{R}^d$. For each point $\\mathbf{x} \\in \\mathbb{R}^d$, we can find $\\mathcal{N}_k(\\mathbf{x})$, its $k$ nearest neighbors in $\\mathcal{X}$ based on a primary distance metric. The SNN similarity measure between two points is defined as the proportion of overlap between the $k$ nearest neighbors of the two points, i.e.,\n",
    "$$\n",
    "S(\\mathbf{x}, \\mathbf{y}) = \\frac{|\\mathcal{N}_k(\\mathbf{x}) \\cap \\mathcal{N}_k(\\mathbf{y})|}{k}.\n",
    "$$\n",
    "\n",
    "This metric can also be motivated as the cosine similarity between the binary set membership vector representation of $\\mathbf{x}$ and $\\mathbf{y}$ (of length $N$), where the $i$-th element is $1$ if $\\mathbf{x_i}$ is in the corresponding $k$ neighbor set, and $0$ otherwise. This similarity measure can be turned into a distance measure in two simple ways:\n",
    "$$\n",
    "d_{\\mathrm{snn}}(\\mathbf{x}, \\mathbf{y}) = 1 - S(\\mathbf{x}, \\mathbf{y}),\n",
    "$$\n",
    "and\n",
    "$$\n",
    "d_{\\mathrm{snn}}(\\mathbf{x}, \\mathbf{y}) = \\arccos(S(\\mathbf{x}, \\mathbf{y})).\n",
    "$$\n",
    "Both versions are reasonable choices and they satisfy the non-negativity and symmetry requirements of a distance metric. The second version can be interpreted as the angle between the two vectors and has range $[0, \\pi]$. Also, the second version satisfies the triangle inequality which can sometimes be a desirable property for a distance metric [1].\n",
    "\n",
    "It has been found that secondary (ranking-based) distance metrics like the SNN can be more robust to the curse of dimensionality compared to primary distance metrics [1].\n",
    "\n",
    "We next show some examples of how to calculate the SNN distance metric.\n",
    "\n",
    "[1] Houle, Michael E., et al. \"Can shared-neighbor distances defeat the curse of dimensionality?.\" International Conference on Scientific and Statistical Database Management. Springer, Berlin, Heidelberg, 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_data import MFA_model\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pynndescent import NNDescent\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants\n",
    "num_proc = max(cpu_count() - 2, 1)\n",
    "seed_rng = np.random.randint(1, high=1001)\n",
    "rho = 0.5\n",
    "k = 20\n",
    "n_neighbors = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data using a mixture of factor analyzers (MFA) model\n",
    "n_components = 10\n",
    "dim = 30\n",
    "dim_latent = 2\n",
    "dim_latent_range = (5, 10)\n",
    "model = MFA_model(n_components, dim, dim_latent_range=dim_latent_range, seed_rng=seed_rng)\n",
    "\n",
    "N = 1000\n",
    "N_test = 100\n",
    "data, labels = model.generate_data(N)\n",
    "data_test, labels_test = model.generate_data(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 19 18:16:39 2019 Building RP forest with 7 trees\n",
      "Tue Nov 19 18:16:39 2019 parallel NN descent for 10 iterations\n",
      "\t 0  /  10\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n"
     ]
    }
   ],
   "source": [
    "# Construct the ANN index to find the k nearest neighbors of each point\n",
    "params = {\n",
    "    'metric': 'euclidean', \n",
    "    'n_neighbors': n_neighbors,\n",
    "    'rho': rho,\n",
    "    'n_trees': None,\n",
    "    'random_state': seed_rng,\n",
    "    'n_jobs': num_proc, \n",
    "    'verbose': True\n",
    "}\n",
    "index = NNDescent(data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=10, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For comparison, let us also construct the exact KNN graph\n",
    "neigh = NearestNeighbors(n_neighbors=k, algorithm='brute', p=2, n_jobs=num_proc)\n",
    "neigh.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/knn_expts/lib/python3.7/site-packages/numba/ir_utils.py:1969: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'forest' of function 'initialise_search'.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../../../../../anaconda3/envs/knn_expts/lib/python3.7/site-packages/pynndescent/pynndescent_.py\", line 72:\n",
      "@numba.njit()\n",
      "def initialise_search(\n",
      "^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    }
   ],
   "source": [
    "# Find the approximate and exact k nearest neighbors of the first two test points\n",
    "nn_indices, _ = index.query(data_test[:2, :], k=k)\n",
    "_, nn_indices_exact = neigh.kneighbors(data_test[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNN distance using the approximate k-NN graph\n",
    "# Construct the set membership binary vector for both test points\n",
    "x = np.zeros(N)\n",
    "x[nn_indices[0, :]] = 1.0\n",
    "y = np.zeros(N)\n",
    "y[nn_indices[1, :]] = 1.0\n",
    "\n",
    "dist_snn = metrics_custom.distance_SNN(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNN distance using the exact k-NN graph\n",
    "x = np.zeros(N)\n",
    "x[nn_indices_exact[0, :]] = 1.0\n",
    "y = np.zeros(N)\n",
    "y[nn_indices_exact[1, :]] = 1.0\n",
    "\n",
    "dist_snn_exact = metrics_custom.distance_SNN(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNN distance between the test points:\n",
      "Using approximate k-NN graph: 0.988432\n",
      "Using exact k-NN graph: 0.988432\n"
     ]
    }
   ],
   "source": [
    "print(\"SNN distance between the test points:\")\n",
    "print(\"Using approximate k-NN graph: {:f}\".format(dist_snn))\n",
    "print(\"Using exact k-NN graph: {:f}\".format(dist_snn_exact))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of SNN distances\n",
    "Next, let us look at a histogram of the SNN distances between randomly drawn pairs of test points. The function `metrics_custom.neighborhood_membership_vectors` can be used to quickly convert the nearest neighbor indices to binary set membership vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the approximate and exact k nearest neighbors of all the test points\n",
    "nn_indices, _ = index.query(data_test, k=k)\n",
    "_, nn_indices_exact = neigh.kneighbors(data_test)\n",
    "\n",
    "# `x_approx` will be numpy array of 0s and 1s, with shape `(N_test, N)` and dtype `np.uint8`\n",
    "x_approx = metrics_custom.neighborhood_membership_vectors(nn_indices, N)\n",
    "x_exact = metrics_custom.neighborhood_membership_vectors(nn_indices_exact, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55481103 0.98843209 1.36943841 1.57079633 1.57079633 1.57079633\n",
      " 1.57079633 1.57079633]\n"
     ]
    }
   ],
   "source": [
    "# Find the SNN distances between all pairs of test points\n",
    "N_pairs = int(0.5 * N_test * (N_test - 1))\n",
    "dist_arr = np.zeros(N_pairs)\n",
    "k = 0\n",
    "for i in range(N_test - 1):\n",
    "    for j in range(i + 1, N_test):\n",
    "        dist_arr[k] = metrics_custom.distance_SNN(x_approx[i, :], x_approx[j, :])\n",
    "        k += 1\n",
    "\n",
    "p = np.percentile(dist_arr, [0, 1, 5, 10, 50, 75, 95, 100])\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
